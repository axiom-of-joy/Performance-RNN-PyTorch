{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PerformanceRNN\n",
    "import torch\n",
    "from torch import nn\n",
    "import distiller\n",
    "from distiller.modules.gru import convert_model_to_distiller_gru\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model and converting to our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in rnn_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in rnn_model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = 'cuda:0'\n",
    "sess_path = \"save/ecomp_w500.sess\"\n",
    "state = torch.load(sess_path)\n",
    "rnn_model = PerformanceRNN(**state['model_config']).to(device)\n",
    "rnn_model.load_state_dict(state['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = convert_model_to_distiller_gru(rnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure model stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distiller.model_summaries import model_summary\n",
    "\n",
    "model_summary(rnn_model,  'compute', dataset=events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that man_model is on GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(man_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the conversion has succeeded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to make sure that both the original and manual models can generate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn_model#quantizer.model.to(device)\n",
    "model.eval()\n",
    "batch_size = 8\n",
    "init = torch.randn(batch_size, model.init_dim).to(device)\n",
    "max_len = 1000\n",
    "controls=None\n",
    "greedy_ratio = 0.7\n",
    "temperature = 1.0\n",
    "\n",
    "import pdb\n",
    "\n",
    "with torch.no_grad():\n",
    "    #pdb.set_trace()\n",
    "    outputs = model.generate(init, max_len,\n",
    "                             controls=controls,\n",
    "                             greedy=greedy_ratio,\n",
    "                             temperature=temperature,\n",
    "                             verbose=True)\n",
    "    \n",
    "\n",
    "outputs = outputs.cpu().numpy().T # [batch, steps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert output to MIDI and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "\n",
    "output_dir = \"quantized_output/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i, output in enumerate(outputs):\n",
    "    name = f'output-{i:03d}.mid'\n",
    "    path = os.path.join(output_dir, name)\n",
    "    n_notes = utils.event_indeces_to_midi_file(output, path)\n",
    "    print(f'===> {path} ({n_notes} notes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantizing the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect activation statistics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model uses activation statistics to determine how big the quantization range is. The bigger the range - the larger the round off error after quantization which leads to accuracy drop.  \n",
    "Our goal is to minimize the range s.t. it contains the absolute most of our data.  \n",
    "After that, we divide the range into chunks of equal size, according to the number of bits, and transform the data according to this scale factor.  \n",
    "Read more on scale factor calculation [in our docs](https://nervanasystems.github.io/distiller/algo_quantization.html).\n",
    "\n",
    "The class `QuantCalibrationStatsCollector` collects the statistics for defining the range $r = max - min$.  \n",
    "\n",
    "Each forward pass, the collector records the values of inputs and outputs, for each layer:\n",
    "- absolute over all batches min, max (stored in `min`, `max`)\n",
    "- average over batches, per batch min, max (stored in `avg_min`, `avg_max`)\n",
    "- mean\n",
    "- std\n",
    "- shape of output tensor  \n",
    "\n",
    "All these values can be used to define the range of quantization, e.g. we can use the absolute `min`, `max` to define the range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `man_model` has the same weights as `rnn_model` (Warning: Running this will move the models to the CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.testing as nptest\n",
    "\n",
    "man_model_weights = man_model.cpu().output_fc.weight.detach().numpy()\n",
    "rnn_model_weights = rnn_model.cpu().output_fc.weight.detach().numpy()\n",
    "nptest.assert_array_almost_equal(man_model_weights, rnn_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `man_model` is on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(man_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My version.\n",
    "import os\n",
    "from distiller.data_loggers import QuantCalibrationStatsCollector, collector_context\n",
    "\n",
    "# Commented line is probably not necessary.\n",
    "#man_model = torch.load('./manual.checkpoint.pth.tar')\n",
    "distiller.utils.assign_layer_fq_names(rnn_model)\n",
    "collector = QuantCalibrationStatsCollector(rnn_model)\n",
    "                                           #inplace_runtime_check=True)\n",
    "                                           #disable_inplace_attrs=True) # I added this last argument.\n",
    "\n",
    "# Random numbers.\n",
    "batch_size = 64\n",
    "max_len = 100\n",
    "\n",
    "\n",
    "with collector_context(collector) as collector:\n",
    "    init = torch.randn(batch_size, rnn_model.init_dim).to(device)\n",
    "    output = rnn_model.generate(init, max_len)\n",
    "    collector.save('performance_rnn_pretrained_stats.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overrides_yaml = \"\"\"\n",
    "#.*eltwise.*:\n",
    "#    fp16: true\n",
    "output_fc_activation:\n",
    "    fp16: true\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distiller.quantization import PostTrainLinearQuantizer, LinearQuantMode\n",
    "from copy import deepcopy\n",
    "# Define the quantizer\n",
    "overrides_yaml = \"\"\"\n",
    "#.*eltwise.*:\n",
    "#    fp16: true\n",
    "output_fc_activation:\n",
    "    fp16: true\n",
    "\"\"\"\n",
    "overrides = distiller.utils.yaml_ordered_load(overrides_yaml)\n",
    "quantizer = PostTrainLinearQuantizer(\n",
    "    deepcopy(rnn_model),\n",
    "    model_activation_stats='stats/performance_rnn_pretrained_stats.yaml',\n",
    "    overrides=overrides,\n",
    "    mode=LinearQuantMode.ASYMMETRIC_SIGNED,\n",
    "    per_channel_wts=True,\n",
    "    clip_acts='AVG'\n",
    ")\n",
    "\n",
    "# Quantizer magic:\n",
    "\n",
    "quantizer.prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerformanceRNN(\n",
       "  (inithid_fc): RangeLinearQuantParamLayerWrapper(\n",
       "    mode=ASYMMETRIC_SIGNED, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=AVG, per_channel_wts=True, scale_approx_mult_bits=None\n",
       "    preset_activation_stats=True\n",
       "    w_scale=PerCh, w_zero_point=PerCh\n",
       "    in_scale=61.0203, in_zero_point=2.0000\n",
       "    out_scale=37.8976, out_zero_point=-16.0000\n",
       "    (wrapped_module): Linear(in_features=32, out_features=1536, bias=True)\n",
       "  )\n",
       "  (inithid_fc_activation): Tanh()\n",
       "  (event_embedding): RangeLinearEmbeddingWrapper(\n",
       "    (wrapped_module): Embedding(240, 240)\n",
       "  )\n",
       "  (concat_input_fc): RangeLinearQuantParamLayerWrapper(\n",
       "    mode=ASYMMETRIC_SIGNED, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=AVG, per_channel_wts=True, scale_approx_mult_bits=None\n",
       "    preset_activation_stats=True\n",
       "    w_scale=PerCh, w_zero_point=PerCh\n",
       "    in_scale=205.7303, in_zero_point=79.0000\n",
       "    out_scale=145.4613, out_zero_point=-22.0000\n",
       "    (wrapped_module): Linear(in_features=265, out_features=512, bias=True)\n",
       "  )\n",
       "  (concat_input_fc_activation): LeakyReLU(negative_slope=0.1, inplace)\n",
       "  (gru): DistillerGRU(512, 512, num_layers=3, dropout=0.30, bidirectional=False)\n",
       "  (output_fc): RangeLinearQuantParamLayerWrapper(\n",
       "    mode=ASYMMETRIC_SIGNED, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=AVG, per_channel_wts=True, scale_approx_mult_bits=None\n",
       "    preset_activation_stats=True\n",
       "    w_scale=PerCh, w_zero_point=PerCh\n",
       "    in_scale=127.5333, in_zero_point=0.0000\n",
       "    out_scale=7.8000, out_zero_point=-13.0000\n",
       "    (wrapped_module): Linear(in_features=1536, out_features=240, bias=True)\n",
       "  )\n",
       "  (output_fc_activation): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_backend', '_parameters', '_buffers', '_backward_hooks', '_forward_hooks', '_forward_pre_hooks', '_state_dict_hooks', '_load_state_dict_pre_hooks', '_modules', 'training', 'event_dim', 'control_dim', 'init_dim', 'hidden_dim', 'gru_layers', 'concat_dim', 'input_dim', 'output_dim', 'primary_event', 'quantizer_metadata'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer.model.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inithid_fc RangeLinearQuantParamLayerWrapper(\n",
      "  mode=ASYMMETRIC_SIGNED, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=AVG, per_channel_wts=True, scale_approx_mult_bits=None\n",
      "  preset_activation_stats=True\n",
      "  w_scale=PerCh, w_zero_point=PerCh\n",
      "  in_scale=61.0203, in_zero_point=2.0000\n",
      "  out_scale=37.8976, out_zero_point=-16.0000\n",
      "  (wrapped_module): Linear(in_features=32, out_features=1536, bias=True)\n",
      ")\n",
      "inithid_fc_activation Tanh()\n",
      "event_embedding RangeLinearEmbeddingWrapper(\n",
      "  (wrapped_module): Embedding(240, 240)\n",
      ")\n",
      "concat_input_fc RangeLinearQuantParamLayerWrapper(\n",
      "  mode=ASYMMETRIC_SIGNED, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=AVG, per_channel_wts=True, scale_approx_mult_bits=None\n",
      "  preset_activation_stats=True\n",
      "  w_scale=PerCh, w_zero_point=PerCh\n",
      "  in_scale=205.7303, in_zero_point=79.0000\n",
      "  out_scale=145.4613, out_zero_point=-22.0000\n",
      "  (wrapped_module): Linear(in_features=265, out_features=512, bias=True)\n",
      ")\n",
      "concat_input_fc_activation LeakyReLU(negative_slope=0.1, inplace)\n",
      "gru DistillerGRU(512, 512, num_layers=3, dropout=0.30, bidirectional=False)\n",
      "output_fc RangeLinearQuantParamLayerWrapper(\n",
      "  mode=ASYMMETRIC_SIGNED, num_bits_acts=8, num_bits_params=8, num_bits_accum=32, clip_acts=AVG, per_channel_wts=True, scale_approx_mult_bits=None\n",
      "  preset_activation_stats=True\n",
      "  w_scale=PerCh, w_zero_point=PerCh\n",
      "  in_scale=127.5333, in_zero_point=0.0000\n",
      "  out_scale=7.8000, out_zero_point=-13.0000\n",
      "  (wrapped_module): Linear(in_features=1536, out_features=240, bias=True)\n",
      ")\n",
      "output_fc_activation Softmax()\n"
     ]
    }
   ],
   "source": [
    "for key, val in quantizer.model._modules.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[  15.,  -25.,  -26.,  ...,  -43.,  -34.,   38.],\n",
       "        [ -24.,  -45.,  -46.,  ...,  -47.,    4.,   69.],\n",
       "        [  -7.,   70., -101.,  ...,   58.,   24.,   33.],\n",
       "        ...,\n",
       "        [ -27.,   11.,  -57.,  ...,  -21.,  -41.,  -55.],\n",
       "        [  40.,   27.,    7.,  ...,   76.,   42.,   56.],\n",
       "        [ -24.,   11.,  -32.,  ...,   19.,  -16.,  -40.]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer.model._modules['gru']._modules['cells'][0]._modules['fc_gate_x'].wrapped_module.__dict__['_parameters']['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EltwiseAdd()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer.model._modules['gru']._modules['cells'][0]._modules['eltwiseadd_gate'].wrapped_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the perplexity of the original and quantized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Dataset\n",
    "from sequence import EventSeq\n",
    "import torch.functional as F\n",
    "\n",
    "data_path = \"dataset/processed/ecomp_piano\"\n",
    "dataset = Dataset(data_path, verbose=True)\n",
    "dataset_size = len(dataset.samples)\n",
    "assert dataset_size > 0\n",
    "\n",
    "# Eventually need to put these in YAML file.\n",
    "controls = None\n",
    "teacher_forcing_ratio = 1.0\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "nnl = nn.NLLLoss(reduction='sum')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window_size = 200\n",
    "stride_size = 10\n",
    "use_transposition = False\n",
    "control_ratio = 1.0\n",
    "event_dim = EventSeq.dim()\n",
    "batch_size = 2\n",
    "\n",
    "batch_gen = dataset.batches(batch_size, window_size, stride_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = quantizer.model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy.testing as nptest\n",
    "import pdb\n",
    "\n",
    "acc_loss = 0\n",
    "N = 0\n",
    "num_iters = 100\n",
    "\n",
    "for iteration, (events, controls) in enumerate(batch_gen):\n",
    "    print(iteration)\n",
    "    if iteration == num_iters:\n",
    "        break\n",
    "        \n",
    "    if use_transposition:\n",
    "        offset = np.random.choice(np.arange(-6, 6))\n",
    "        events, controls = utils.transposition(events, controls, offset)\n",
    "\n",
    "    events = torch.LongTensor(events).to(device)\n",
    "    assert events.shape[0] == window_size\n",
    "\n",
    "    if np.random.random() < control_ratio:\n",
    "        controls = torch.FloatTensor(controls).to(device)\n",
    "        assert controls.shape[0] == window_size\n",
    "    else:\n",
    "        controls = None\n",
    "\n",
    "    init = torch.randn(batch_size, model.init_dim).to(device)\n",
    "    outputs = model.generate(init, window_size, events=events[:-1], controls=controls,\n",
    "                             teacher_forcing_ratio=teacher_forcing_ratio, output_type='logit')\n",
    "    \n",
    "\n",
    "    assert outputs.shape[:2] == events.shape[:2]\n",
    "\n",
    "    \n",
    "    loss1 = loss_function(outputs.view(-1, event_dim), events.view(-1))\n",
    "    pred = log_softmax(outputs.view(-1, event_dim))\n",
    "    n = pred.shape[0]\n",
    "    loss2 = nnl(pred, events.view(-1))\n",
    "    acc_loss += loss2\n",
    "    N += n\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "   \n",
    "    # Check to make sure we're calculating the correct loss.\n",
    "    nptest.assert_array_almost_equal(loss1.cpu().detach().numpy(), loss2.cpu().detach().numpy() / n)\n",
    "\n",
    "\n",
    "\n",
    "acc_cross_entropy_loss = acc_loss / N\n",
    "perplexity = acc_cross_entropy_loss.exp()\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Quant Stats Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Dataset\n",
    "from sequence import EventSeq\n",
    "import torch.functional as F\n",
    "\n",
    "data_path = \"dataset/processed/ecomp_piano\"\n",
    "dataset = Dataset(data_path, verbose=True)\n",
    "dataset_size = len(dataset.samples)\n",
    "assert dataset_size > 0\n",
    "\n",
    "# Eventually need to put these in YAML file.\n",
    "controls = None\n",
    "teacher_forcing_ratio = 1.0\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "nnl = nn.NLLLoss(reduction='sum')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window_size = 200\n",
    "stride_size = 10\n",
    "use_transposition = False\n",
    "control_ratio = 1.0\n",
    "event_dim = EventSeq.dim()\n",
    "batch_size = 2\n",
    "\n",
    "batch_gen = dataset.batches(batch_size, window_size, stride_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = rnn_model #quantizer.model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy.testing as nptest\n",
    "import pdb\n",
    "import os\n",
    "from distiller.data_loggers import QuantCalibrationStatsCollector, collector_context\n",
    "\n",
    "acc_loss = 0\n",
    "N = 0\n",
    "num_iters = 100\n",
    "\n",
    "# Collect stats.\n",
    "distiller.utils.assign_layer_fq_names(rnn_model)\n",
    "collector = QuantCalibrationStatsCollector(rnn_model)\n",
    "                                           #inplace_runtime_check=True)\n",
    "\n",
    "\n",
    "with collector_context(collector) as collector:\n",
    "\n",
    "\n",
    "    for iteration, (events, controls) in enumerate(batch_gen):\n",
    "        print(iteration)\n",
    "\n",
    "        if iteration == num_iters:\n",
    "            break\n",
    "\n",
    "        if use_transposition:\n",
    "            offset = np.random.choice(np.arange(-6, 6))\n",
    "            events, controls = utils.transposition(events, controls, offset)\n",
    "\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "            \n",
    "        events = torch.LongTensor(events).to(device)\n",
    "        assert events.shape[0] == window_size\n",
    "\n",
    "        if np.random.random() < control_ratio:\n",
    "            controls = torch.FloatTensor(controls).to(device)\n",
    "            assert controls.shape[0] == window_size\n",
    "        else:\n",
    "            controls = None\n",
    "\n",
    "        init = torch.randn(batch_size, model.init_dim).to(device)\n",
    "        outputs = model.generate(init, window_size, events=events[:-1], controls=controls,\n",
    "                                 teacher_forcing_ratio=teacher_forcing_ratio, output_type='logit')\n",
    "\n",
    "\n",
    "        assert outputs.shape[:2] == events.shape[:2]\n",
    "\n",
    "\n",
    "\n",
    "    # Save stats.\n",
    "    collector.save('performance_rnn_pretrained_stats.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
